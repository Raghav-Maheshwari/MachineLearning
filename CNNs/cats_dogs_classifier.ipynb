{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "from scipy.ndimage import imread\n",
    "import cv2\n",
    "import sklearn.utils\n",
    "\n",
    "DATA_PATH = './data/train/'\n",
    "TEST_PERCENT = 0.4;\n",
    "SELECT_SUBSET_PERCENT = 0.15\n",
    "\n",
    "#cat and dog images are od variable size\n",
    "RESIZE_WIDTH = 32\n",
    "RESIZE_HEIGHT = 32\n",
    "EPOCHS = 5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Going to load 3538 files\n",
      "Have loaded 1000 samples\n",
      "Have loaded 2000 samples\n",
      "Have loaded 3000 samples\n",
      "Train set has dimensionality (3362, 32, 32, 3)\n",
      "Test set has dimensionality (176, 32, 32, 3)\n"
     ]
    }
   ],
   "source": [
    "X = []\n",
    "Y = []\n",
    "\n",
    "files = os.listdir(DATA_PATH)\n",
    "# Shuffle to select equal number of cat and god images\n",
    "shuffled_files = sklearn.utils.shuffle(files)\n",
    "select_count = int(len(shuffled_files) * SELECT_SUBSET_PERCENT)\n",
    "\n",
    "print('Going to load %i files' % select_count)\n",
    "subset_files_select = shuffled_files[:select_count]\n",
    "DISPLAY_COUNT = 1000\n",
    "\n",
    "for i, input_file in enumerate(subset_files_select):\n",
    "    if i % DISPLAY_COUNT == 0 and i != 0:\n",
    "        print('Have loaded %i samples' %i)\n",
    "        \n",
    "    img = imread(DATA_PATH + input_file)\n",
    "    img = cv2.resize(img, (RESIZE_WIDTH, RESIZE_HEIGHT), interpolation=cv2.INTER_CUBIC)\n",
    "    X.append(img)\n",
    "    \n",
    "    # labelling the data\n",
    "    if 'cat' == input_file.split('.')[0]:\n",
    "        Y.append(0.0)\n",
    "    else:\n",
    "        Y.append(1.0)\n",
    "    \n",
    "X = np.array(X)\n",
    "Y = np.array(Y)\n",
    "\n",
    "test_size = int(len(X) * 0.05)\n",
    "\n",
    "test_X = X[:test_size]\n",
    "test_Y = Y[:test_size]\n",
    "train_X = X[test_size:]\n",
    "train_Y = Y[test_size:]\n",
    "\n",
    "print('Train set has dimensionality %s' % str(train_X.shape))\n",
    "print('Test set has dimensionality %s' % str(test_X.shape))\n",
    "\n",
    "# Apply some normalization here.\n",
    "train_X = train_X.astype('float32')\n",
    "test_X = test_X.astype('float32')\n",
    "train_X /= 255\n",
    "test_X /= 255\n",
    "    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import necessary layers.\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Input, Dropout, Flatten, Conv2D, MaxPooling2D, Dense, Activation\n",
    "from keras.optimizers import RMSprop\n",
    "from keras.layers.normalization import BatchNormalization\n",
    "from keras.constraints import max_norm\n",
    "\n",
    "\n",
    "model = Sequential()\n",
    "\n",
    "# Define the network\n",
    "model.add(Conv2D(32, (3, 3), padding='same', kernel_initializer='glorot_normal', input_shape=(RESIZE_WIDTH, RESIZE_HEIGHT, 3)))\n",
    "#model.add(BatchNormalization(axis=-1))\n",
    "model.add(Activation('relu'))\n",
    "model.add(Conv2D(32, (3, 3), padding='same', kernel_initializer='glorot_normal'))\n",
    "#model.add(BatchNormalization(axis=-1))\n",
    "model.add(Activation('relu'))\n",
    "model.add(MaxPooling2D(pool_size=(2,2)))\n",
    "\n",
    "model.add(Conv2D(64,(3, 3), padding='same', kernel_initializer='glorot_normal'))\n",
    "#model.add(BatchNormalization(axis=-1))\n",
    "model.add(Activation('relu'))\n",
    "model.add(Conv2D(64, (3, 3), padding='same', kernel_initializer='glorot_normal'))\n",
    "#model.add(BatchNormalization(axis=-1))\n",
    "model.add(Activation('relu'))\n",
    "model.add(MaxPooling2D(pool_size=(2,2)))\n",
    "\n",
    "model.add(Flatten())\n",
    "\n",
    "# Fully connected layer\n",
    "model.add(Dense(512, kernel_initializer='glorot_normal'))\n",
    "#model.add(BatchNormalization())\n",
    "model.add(Activation('relu'))\n",
    "model.add(Dropout(0.5))\n",
    "model.add(Dense(1, kernel_initializer='glorot_normal'))\n",
    "model.add(Activation('sigmoid'))\n",
    "\n",
    "\n",
    "# Defining loss and optimizer\n",
    "optimizer = RMSprop(lr=1e-4)\n",
    "loss = 'binary_crossentropy'\n",
    "model.compile(loss=loss, optimizer=optimizer, metrics=['accuracy'])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 2689 samples, validate on 673 samples\n",
      "Epoch 1/5\n",
      "2689/2689 [==============================] - 28s - loss: 0.6877 - acc: 0.5400 - val_loss: 0.6919 - val_acc: 0.5364\n",
      "Epoch 2/5\n",
      "2689/2689 [==============================] - 24s - loss: 0.6820 - acc: 0.5444 - val_loss: 0.6878 - val_acc: 0.5171\n",
      "Epoch 3/5\n",
      "2689/2689 [==============================] - 23s - loss: 0.6771 - acc: 0.5608 - val_loss: 0.7285 - val_acc: 0.5364\n",
      "Epoch 4/5\n",
      "2689/2689 [==============================] - 25s - loss: 0.6740 - acc: 0.5664 - val_loss: 0.6743 - val_acc: 0.5899\n",
      "Epoch 5/5\n",
      "2240/2689 [=======================>......] - ETA: 3s - loss: 0.6586 - acc: 0.6094"
     ]
    }
   ],
   "source": [
    "batch_size = 64\n",
    "\n",
    "# test the network:\n",
    "model.fit(train_X, train_Y, batch_size=batch_size, epochs=EPOCHS, validation_split=0.2, verbose=1, shuffle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "loss, acc = model.evaluate(test_X, test_Y, batch_size=batch_size, verbose=1)\n",
    "\n",
    "print('')\n",
    "print('Got %.2f%% accuracy' % (acc * 100.))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:caispp]",
   "language": "python",
   "name": "conda-env-caispp-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
